
# AIN 214 PA3 on Data Prepocessing and Regression
# THE STUDENT INFO
## Student Name: Bora Dere
## Student ID: 2220765021
# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import math

# Load the dataset
# Replace 'path_to_dataset' with the actual file path
path_to_dataset = 'housing.csv'
housing_df = pd.read_csv(path_to_dataset)
# We will deal with the famous California Housing Prices dataset from Kaggle. [1]
# 1. Data Preprocessing (50 Pts)
## 1.1. Explaratory Data Analysis (10 Pts)

* Check for missing values
* Visualize the features with any relevant plots to understand the distribution of data
* Visualize the target variable with respect to the features 
* Visualize the correlation between the features using a heatmap
* Comment on any findings
housing_df = pd.DataFrame(housing_df)
### 1.1.1 Checking for missing values
housing_df.isnull().sum()
Dropping the missing values...
housing_df = housing_df.dropna()
housing_df.isnull().sum()
### 1.1.2 Visualizing the features
- For bin count, we can use Sturge's formula.
- For quantiative data, histogram would be convenient.
- stat='density' is used, so that the sum of the bars will add up to 1, thus truly visualizing the distribution. (It would not affect the overall shape but I thought it is more convenient.)
- For qualitative data, pie graph was preferred at the earlier stages.
#### A) Visualizing the Longitude Feature
bin_count = int(1 + 3.3*math.log(housing_df['longitude'].count()))

plt.figure(figsize=(18, 10))
sns.histplot(housing_df['longitude'], bins=bin_count, color='darkslateblue', stat='density')
#### B) Visualizing the Latitude Feature
bin_count = int(1 + 3.3*math.log(housing_df['latitude'].count()))

plt.figure(figsize=(18, 10))
sns.histplot(housing_df['latitude'], bins=bin_count, color='darkslateblue', stat='density')
#### C) Visualizing the Housing Median Range Feature
bin_count = int(1 + 3.3*math.log(housing_df['housing_median_age'].count()))

plt.figure(figsize=(18, 10))
sns.histplot(housing_df['housing_median_age'], bins=bin_count, color='darkslateblue', stat='density')
#### D) Visualizing the Total Rooms Feature
bin_count = int(1 + 3.3*math.log(housing_df['total_rooms'].count()))

plt.figure(figsize=(18, 10))
sns.histplot(housing_df['total_rooms'], bins=bin_count, color='darkslateblue', stat='density')
#### E) Visualizing the Total Bedrooms Feature
bin_count = int(1 + 3.3*math.log(housing_df['total_bedrooms'].count()))

plt.figure(figsize=(18, 10))
sns.histplot(housing_df['total_bedrooms'], bins=bin_count, color='darkslateblue')
#### F) Visualizing the Population Feature
bin_count = int(1 + 3.3*math.log(housing_df['population'].count()))

plt.figure(figsize=(18, 10))
sns.histplot(housing_df['population'], bins=bin_count, color='darkslateblue', stat='density')
#### G) Visualizing the Households Feature
bin_count = int(1 + 3.3*math.log(housing_df['households'].count()))

plt.figure(figsize=(18, 10))
sns.histplot(housing_df['households'], bins=bin_count, color='darkslateblue', stat='density')
#### H) Visualizing the Median Income Feature
bin_count = int(1 + 3.3*math.log(housing_df['median_income'].count()))

plt.figure(figsize=(18, 10))
sns.histplot(housing_df['median_income'], bins=bin_count, color='darkslateblue', stat='density')
#### I) Visualizing the Median House Value Feature
bin_count = int(1 + 3.3*math.log(housing_df['median_house_value'].count()))

plt.figure(figsize=(18, 10))
sns.histplot(housing_df['median_house_value'], bins=bin_count, color='darkslateblue', stat='density')
#### J) Visualizing the Ocean Proximity Feature
plt.figure(figsize=(18, 10))
plt.pie(housing_df['ocean_proximity'].value_counts(), labels=housing_df['ocean_proximity'].unique(), colors=['#f72585', '#7209b7', '#3a0ca3', '#4361ee', '#4cc9f0'], autopct='%1.2f%%', shadow=True)
As seen, value 'ISLAND' occurs so less in the dataset that it almost does not take any space on the pie graph. So, let's put them in a bar plot to see if anything changes.
plt.figure(figsize=(18, 10))
sns.barplot(y=housing_df['ocean_proximity'].value_counts(), x=housing_df['ocean_proximity'].unique(), hue= housing_df['ocean_proximity'].unique(), palette=['#f72585', '#7209b7', '#3a0ca3', '#4361ee', '#4cc9f0'], legend=False)
It did not make any difference. That is because 'ISLAND' has so little occurence in the dataset. 
print(f"Ocean proximity is occured in this dataset for {len(housing_df[housing_df['ocean_proximity'] == 'ISLAND'])} times.")
*Ocean proximity is occured in this dataset for 5 times.*

That tells us something. The closest value to 5 is more than 2000. So, it is natural not being able to see it distinctively. 
### 1.1.3 Visualizing the target variable with respect to features
target = 'median_house_value'
#### 1.1.3.1 With respect to Latitude and Longitude
plt.figure(figsize=(18, 10))
sns.scatterplot(data=housing_df, x='longitude', y='latitude', hue=target, palette='plasma_r')
#### 1.1.3.2 With respect to Ocean Proximity
plt.figure(figsize=(18, 10))
sns.boxplot(data=housing_df, x='ocean_proximity', y=target, palette=['#f72585', '#7209b7', '#3a0ca3', '#4361ee', '#4cc9f0'], hue='ocean_proximity', showfliers=False)
#### 1.1.3.3 With respect to remaining features
fig, axes = plt.subplots(2, 3, figsize=(18, 10), sharey=True)

fig.suptitle('With respect to housing_median_age, total_rooms, total_bedrooms, population, households and median_income')

sns.scatterplot(ax=axes[0,0], data=housing_df, x='housing_median_age', y=target, hue=target, palette='plasma_r', legend=False)
sns.scatterplot(ax=axes[0,1], data=housing_df, x='total_rooms', y=target, hue=target, palette='plasma_r', legend=False)
sns.scatterplot(ax=axes[0,2], data=housing_df, x='total_bedrooms', y=target, hue=target, palette='plasma_r', legend=False)
sns.scatterplot(ax=axes[1,0], data=housing_df, x='population', y=target, hue=target, palette='plasma_r', legend=False)
sns.scatterplot(ax=axes[1,1], data=housing_df, x='households', y=target, hue=target, palette='plasma_r', legend=False)
sns.scatterplot(ax=axes[1,2], data=housing_df, x='median_income', y=target, hue=target, palette='plasma_r', legend=False)
### 1.1.4 Visualizing the correlation matrix
corr_matrix = housing_df.select_dtypes(include=[np.number]).corr()

plt.figure(figsize=(10, 10))
sns.heatmap(corr_matrix, annot=True, cmap='plasma_r', square=True)
### 1.1.5 Commentary
- Based on the first histogram plots, total rooms, total bedrooms, population, households features have really uneven distributions. Median income may also be added to that list. It is not giving us any clues to infer but it is worth mentioning.

- In ocean proximity, island value is by far the least occured one. This is totally understandable and expectable, since the houses on islands are in minority, generally.

- About latitude and longitude: While there isn't a specific correlation between these features and house value, generally speaking, houses tend to be more expensive along a diagonal line. This line begins roughly at a latitude of 38, and as latitude decreases (moving south), longitude increases (moving east). This can be easily understood and accepted once the map of California is inspected. This specific line actually represents the seaside (more precisely, oceanside) part of the city. So, naturally, houses located along this line are more expensive.

- Based on the only boxplot until here, houses near the water resources are more expensive due to their greater demand. 

- Correlation matrix gives us some opinions but not clear ones. They are not interpretable by themselves, but just some helper points.
## 1.2. Outlier Detection (15 Pts)
* Choose an outlier detection method and apply it to the data.
* Explain your method and why you choose it.
### 1.2.1 Outlier detection reasoning
- For outlier detection, IQR (interquartile range) method is used because it is easy to use and seen as a good practice in statistics.
def outlier_finder(data):
    Q1 = data.quantile(0.25)
    Q3 = data.quantile(0.75)
    IQR = Q3 - Q1

    inner_lower_fence = Q1 - 1.5*IQR
    inner_upper_fence = Q3 + 1.5*IQR

    outer_lower_fence = Q1 - 3*IQR
    outer_upper_fence = Q3 + 3*IQR

    mild_outliers = [i for i in data if (i < inner_lower_fence and i > outer_lower_fence) or (i > inner_upper_fence and i < outer_upper_fence)]
    extreme_outliers = [i for i in data if i < outer_lower_fence or i > outer_upper_fence]

    return [mild_outliers, extreme_outliers]


def outlier_printer(outliers, feature):
    mild_outliers = outliers[0]
    extreme_outliers = outliers[1]
    
    if len(mild_outliers) != 0:
        # to achieve a better output format
        o1 = f"There are {len(mild_outliers)} mild outliers in the {feature} feature."
        o2 = f"{mild_outliers[0]} is a mild outlier for the {feature} feature."

        print(o1)
        print("-"*len(o1 if len(o1) > len(o2) else o2))
        
        for i in mild_outliers:
            print(f"{i} is a mild outlier for the {feature} feature.")

        print()

    if len(extreme_outliers) != 0:
        o1 = f"There are {len(extreme_outliers)} extreme outliers in the {feature} feature."
        o2 = f"{extreme_outliers[0]} is an extreme outlier for the {feature} feature."

        print(o1)
        print("-"*len(o1 if len(o1) > len(o2) else o2))
        
        for i in extreme_outliers:
            print(f"{i} is an extreme outlier for the {feature} feature.")
### 1.2.2 Outlier detections
#### 1.2.2.1 Outlier detection for Longitude
longitude_data = housing_df['longitude']
longitude_outliers = outlier_finder(longitude_data)

outlier_printer(longitude_outliers, 'longitude')
#### 1.2.2.2 Outlier detection for Latitude
latitude_data = housing_df['latitude']
latitude_outliers = outlier_finder(latitude_data)

outlier_printer(latitude_outliers, 'latitude')
#### 1.2.2.3 Outlier detection for Housing Median Age
housing_median_age_data = housing_df['housing_median_age']
housing_median_age_outliers = outlier_finder(housing_median_age_data)

outlier_printer(housing_median_age_outliers, 'housing_median_age')
#### 1.2.2.4 Outlier detection for Total Rooms
total_rooms_data = housing_df['total_rooms']
total_rooms_outliers = outlier_finder(total_rooms_data)

outlier_printer(total_rooms_outliers, 'total_rooms')
#### 1.2.2.5 Outlier detection for Total Bedrooms
total_bedrooms_data = housing_df['total_bedrooms']
total_bedrooms_outliers = outlier_finder(total_bedrooms_data)

outlier_printer(total_bedrooms_outliers, 'total_bedrooms')
#### 1.2.2.6 Outlier detection for Population
population_data = housing_df['population']
population_outliers = outlier_finder(population_data)

outlier_printer(population_outliers, 'population')
#### 1.2.2.7 Outlier detection for Households
households_data = housing_df['households']
households_outliers = outlier_finder(households_data)

outlier_printer(households_outliers, 'households')
#### 1.2.2.8 Outlier detection for Median Income
median_income_data = housing_df['median_income']
median_income_outliers = outlier_finder(median_income_data)

outlier_printer(median_income_outliers, 'median_income')
#### 1.2.2.9 Outlier detection for Ocean Proximity
For Ocean Proximity, since it is categorical, we can use the values' frequencies for IQR calculations.
ocean_proximity_frequency = list(housing_df['ocean_proximity'].value_counts().items())
ocean_proximity_frequency 
freq_list = sorted([i[1] for i in ocean_proximity_frequency])
freq_list
Q1 = np.quantile(freq_list, 0.25)
Q3 = np.quantile(freq_list, 0.75)
IQR = Q3 - Q1

inner_lower_fence = Q1 - 1.5*IQR
inner_upper_fence = Q3 + 1.5*IQR

outer_lower_fence = Q1 - 3*IQR
outer_upper_fence = Q3 + 3*IQR

mild_outliers = [i for i in freq_list if (i < inner_lower_fence and i > outer_lower_fence) or (i > inner_upper_fence and i < outer_upper_fence)]
extreme_outliers = [i for i in freq_list if i < outer_lower_fence or i > outer_upper_fence]

print(f"There are {len(mild_outliers)} mild outliers in the ocean_proximity feature.")
print(f"There are {len(extreme_outliers)} extreme outliers in the ocean_proximity feature.")
## 1.3. Outlier Handling (15 Pts)
Try the following methods to handle outliers, creating checkpoints for each. Additionally, visualize the final data distribution after each method to identify any significant changes
1. Keep the dataset as is - take the original checkpoint for baseline comparison.
2. Outlier removal
3. Mean Imputation (Use Mode imputation for categorical variables)
4. Median Imputation (Use Mode imputation for categorical variables)
### 1.3.1 Original checkpoint
housing_df.to_csv('original_checkpoint.csv', index=False, mode='w')
### 1.3.2 Outlier removal
feature_list = list(housing_df.drop(['median_house_value', 'ocean_proximity'], axis=1))
feature_outlier_list = [longitude_outliers, latitude_outliers, housing_median_age_outliers, total_rooms_outliers, total_bedrooms_outliers, population_outliers, households_outliers, median_income_outliers]

outlier_removed_checkpoint = housing_df.copy()

for i in range(len(feature_list)):
    outlier_removed_checkpoint = outlier_removed_checkpoint[~outlier_removed_checkpoint[feature_list[i]].isin(feature_outlier_list[i][0])]
    outlier_removed_checkpoint = outlier_removed_checkpoint[~outlier_removed_checkpoint[feature_list[i]].isin(feature_outlier_list[i][1])]

outlier_removed_checkpoint.to_csv('outlier_removed_checkpoint.csv', index=False, mode='w')
### 1.3.3 Mean Imputation
Since there are not any outliers in the Ocean Proximity column, we can keep using the *feature_list*.
for i in range(len(feature_list)):
    print(f"Mean for {feature_list[i]} is {housing_df[feature_list[i]].mean()}.")
mean_imputed_checkpoint = housing_df.copy()

for i in range(len(feature_list)):
    mean_imputed_checkpoint[feature_list[i]] = mean_imputed_checkpoint[feature_list[i]].apply(lambda x: housing_df[feature_list[i]].mean() if x in feature_outlier_list[i][0] or x in feature_outlier_list[i][1] else x)

mean_imputed_checkpoint.to_csv('mean_imputed_checkpoint.csv', index=False, mode='w')
### 1.3.4 Median Imputation
for i in range(len(feature_list)):
    print(f"Median for {feature_list[i]} is {housing_df[feature_list[i]].median()}.")
median_imputed_checkpoint = housing_df.copy()

for i in range(len(feature_list)):
    median_imputed_checkpoint[feature_list[i]] = median_imputed_checkpoint[feature_list[i]].apply(lambda x: housing_df[feature_list[i]].median() if x in feature_outlier_list[i][0] or x in feature_outlier_list[i][1] else x)

median_imputed_checkpoint.to_csv('median_imputed_checkpoint.csv', index=False, mode='w')
## 1.4. Encode the Ordinal Features with Ordinal Encoding (2 Pts)
# encode the ordinal features with ordinal encoding
from sklearn.preprocessing import OrdinalEncoder

ordinal_encoder = OrdinalEncoder()

ordinal_encoder.fit(housing_df[['ocean_proximity']])

original_encoded = housing_df.copy()
original_encoded['ocean_proximity'] = ordinal_encoder.transform(original_encoded[['ocean_proximity']])

outlier_removed_encoded = outlier_removed_checkpoint.copy()
outlier_removed_encoded['ocean_proximity'] = ordinal_encoder.transform(outlier_removed_encoded[['ocean_proximity']])

mean_imputed_encoded = mean_imputed_checkpoint.copy()
mean_imputed_encoded['ocean_proximity'] = ordinal_encoder.transform(mean_imputed_encoded[['ocean_proximity']])

median_imputed_encoded = median_imputed_checkpoint.copy()
median_imputed_encoded['ocean_proximity'] = ordinal_encoder.transform(median_imputed_encoded[['ocean_proximity']])
## 1.5. Manually shuffle the dataset and split it into training (70%) and testing (30%) sets. Write your own code for shuffling and splitting, avoiding the use of pre-defined functions like train_test_split." (8 Pts)

You  cannot use scikit-learn's shuffle.
def my_train_test_split(data, train_size=0.7):
    train_data = data.sample(frac=train_size, random_state=42)
    test_data = data.drop(train_data.index)
    return train_data, test_data
# 2. REGRESSION (50 Pts)
* Target value: median_house_value
* Predictors: The rest
## 2.1. kNN Regression (20 Pts)
* For each version of the dataset (original, outlier-removed, mean-imputed, median-imputed), execute the following steps:"
    * Split the data into train and test sets
    * Create an instance of kNN with a number of neighbors between 1-30, then fit kNN regression model to train data. Predict the test set and calculate the MSE value for each k. Plot the MSE vs k curve to decide on the optimal k. Additionally, report the R-squared value for the optimal k.
* Compare the MSE values for each dataset and comment on the results. Which dataset gives the best result? Why do you think that is?

You can use scikit-learn's KNeighborsRegressor.
import sklearn
from sklearn.neighbors import KNeighborsRegressor
### 2.1.1 kNN Regression for Original Data
original_train_data, original_test_data = my_train_test_split(original_encoded)

original_knn_models = [KNeighborsRegressor(n_neighbors=i) for i in range(1, 31)]

for i in range(len(original_knn_models)):
    original_knn_models[i].fit(original_train_data.drop(['median_house_value'], axis=1), original_train_data['median_house_value'])

original_knn_predictions = [original_knn_models[i].predict(original_test_data.drop(['median_house_value'], axis=1)) for i in range(len(original_knn_models))]
original_knn_mse = [sklearn.metrics.mean_squared_error(original_test_data['median_house_value'], original_knn_predictions[i]) for i in range(len(original_knn_models))]

plt.figure(figsize=(18, 10))
plt.plot(original_knn_mse, color='darkslateblue')
plt.xlabel('k Values')
plt.ylabel('MSE Values')
plt.title('k Values vs MSE Values for Original Data')
plt.show()
best_k = original_knn_mse.index(min(original_knn_mse)) + 1
print(f"Best k value for original data is {best_k}.")
MSE values keep getting lower and lower until some point. For original data, that point is 17. Beyond that, MSE sometimes changes so slightly that it is almost impossible to observe. 
original_r2 = sklearn.metrics.r2_score(original_test_data['median_house_value'], original_knn_predictions[16])
print(f"R2 score for original data is {original_r2}.")
### 2.1.2 kNN Regression for Outlier Removed Data
outlier_removed_train_data, outlier_removed_test_data = my_train_test_split(outlier_removed_encoded)

outlier_removed_knn_models = [KNeighborsRegressor(n_neighbors=i) for i in range(1, 31)]

for i in range(len(outlier_removed_knn_models)):
    outlier_removed_knn_models[i].fit(outlier_removed_train_data.drop(['median_house_value'], axis=1), outlier_removed_train_data['median_house_value'])

outlier_removed_knn_predictions = [outlier_removed_knn_models[i].predict(outlier_removed_test_data.drop(['median_house_value'], axis=1)) for i in range(len(outlier_removed_knn_models))]
outlier_removed_knn_mse = [sklearn.metrics.mean_squared_error(outlier_removed_test_data['median_house_value'], outlier_removed_knn_predictions[i]) for i in range(len(outlier_removed_knn_models))]

plt.figure(figsize=(18, 10))
plt.plot(outlier_removed_knn_mse, color='darkslateblue')
plt.xlabel('k Values')
plt.ylabel('MSE Values')
plt.title('k Values vs MSE Values for Outlier Removed Data')
plt.show()
best_k = outlier_removed_knn_mse.index(min(outlier_removed_knn_mse)) + 1
print(f"Best k value for outlier removed data is {best_k}.")
MSE values keep getting lower and lower until some point. For outlier removed data, that point is 27. Beyond that, MSE sometimes changes so slightly that it is almost impossible to observe. 
outlier_removed_r2 = sklearn.metrics.r2_score(outlier_removed_test_data['median_house_value'], outlier_removed_knn_predictions[26])
print(f"R2 score for outlier removed data is {outlier_removed_r2}.")
### 2.1.3 kNN Regression for Mean Imputed Data
mean_imputed_train_data, mean_imputed_test_data = my_train_test_split(mean_imputed_encoded)

mean_imputed_knn_models = [KNeighborsRegressor(n_neighbors=i) for i in range(1, 31)]

for i in range(len(mean_imputed_knn_models)):
    mean_imputed_knn_models[i].fit(mean_imputed_train_data.drop(['median_house_value'], axis=1), mean_imputed_train_data['median_house_value'])

mean_imputed_knn_predictions = [mean_imputed_knn_models[i].predict(mean_imputed_test_data.drop(['median_house_value'], axis=1)) for i in range(len(mean_imputed_knn_models))]
mean_imputed_knn_mse = [sklearn.metrics.mean_squared_error(mean_imputed_test_data['median_house_value'], mean_imputed_knn_predictions[i]) for i in range(len(mean_imputed_knn_models))]

plt.figure(figsize=(18, 10))
plt.plot(mean_imputed_knn_mse, color='darkslateblue')
plt.xlabel('k Values')
plt.ylabel('MSE Values')
plt.title('k Values vs MSE Values for Mean Imputed Data')
plt.show()
best_k = mean_imputed_knn_mse.index(min(mean_imputed_knn_mse)) + 1
print(f"Best k value for mean imputed data is {best_k}.")
MSE values keep getting lower and lower until some point. For mean imputed data, that point is 17. Beyond that, MSE sometimes changes so slightly that it is almost impossible to observe. 
mean_imputed_r2 = sklearn.metrics.r2_score(mean_imputed_test_data['median_house_value'], mean_imputed_knn_predictions[16])
print(f"R2 score for mean imputed data is {mean_imputed_r2}.")
### 2.1.4 kNN Regression for Median Imputed Data
median_imputed_train_data, median_imputed_test_data = my_train_test_split(median_imputed_encoded)

median_imputed_knn_models = [KNeighborsRegressor(n_neighbors=i) for i in range(1, 31)]

for i in range(len(median_imputed_knn_models)):
    median_imputed_knn_models[i].fit(median_imputed_train_data.drop(['median_house_value'], axis=1), median_imputed_train_data['median_house_value'])

median_imputed_knn_predictions = [median_imputed_knn_models[i].predict(median_imputed_test_data.drop(['median_house_value'], axis=1)) for i in range(len(median_imputed_knn_models))]
median_imputed_knn_mse = [sklearn.metrics.mean_squared_error(median_imputed_test_data['median_house_value'], median_imputed_knn_predictions[i]) for i in range(len(median_imputed_knn_models))]

plt.figure(figsize=(18, 10))
plt.plot(median_imputed_knn_mse, color='darkslateblue')
plt.xlabel('k Values')
plt.ylabel('MSE Values')
plt.title('k Values vs MSE Values for Median Imputed Data')
plt.show()
best_k = median_imputed_knn_mse.index(min(median_imputed_knn_mse)) + 1
print(f"Best k value for median imputed data is {best_k}.")
MSE values keep getting lower and lower until some point. For median imputed data, that point is 18. Beyond that, MSE sometimes changes so slightly that it is almost impossible to observe. But since it is not wise to use an even k value, we can use 17 instead.
median_imputed_r2 = sklearn.metrics.r2_score(median_imputed_test_data['median_house_value'], median_imputed_knn_predictions[16])
print(f"R2 score for median imputed data is {median_imputed_r2}.")
### 2.1.5 Commentary
print(f"The best r2 score is original r2 with the value of {max([original_r2, outlier_removed_r2, mean_imputed_r2, median_imputed_r2])}.")
To choose the dataset wiith the best results, we can primitively take and compare the average MSE values for each dataset.
original_mse_avg = sum(original_knn_mse)/len(original_knn_mse)
outlier_removed_mse_avg = sum(outlier_removed_knn_mse)/len(outlier_removed_knn_mse)
mean_imputed_mse_avg = sum(mean_imputed_knn_mse)/len(mean_imputed_knn_mse)
median_imputed_mse_avg = sum(median_imputed_knn_mse)/len(median_imputed_knn_mse)

print(f"The dataset with the lowest average MSE is the outlier removed dataset with the value of {min([original_mse_avg, outlier_removed_mse_avg, mean_imputed_mse_avg, median_imputed_mse_avg])}.")
Just removing the outliers seems like a better option than mean or median imputing. That may be caused by mean or median imputation being really basic ways to trim the outliers.
## 2.2. Linear Regression (20 Pts)
* For each version of the dataset (original, outlier removal, mean imputation, median imputation), do the following:
    * Split the data into train and test sets
    * Fit a Linear Regression model to train data. Predict the test set and calculate the MSE value.
from sklearn.linear_model import LinearRegression
### 2.2.1 Linear Regression for Original Data
original_lr_model = LinearRegression()
original_lr_model.fit(original_train_data.drop(['median_house_value'], axis=1), original_train_data['median_house_value'])
original_lr_predictions = original_lr_model.predict(original_test_data.drop(['median_house_value'], axis=1))
original_lr_mse = sklearn.metrics.mean_squared_error(original_test_data['median_house_value'], original_lr_predictions)
original_lr_mse
original_lr_model_r2 = sklearn.metrics.r2_score(original_test_data['median_house_value'], original_lr_predictions)
original_lr_model_r2
### 2.2.2 Linear Regression for Outlier Removed Data
outlier_removed_lr_model = LinearRegression()
outlier_removed_lr_model.fit(outlier_removed_train_data.drop(['median_house_value'], axis=1), outlier_removed_train_data['median_house_value'])
outlier_removed_lr_predictions = outlier_removed_lr_model.predict(outlier_removed_test_data.drop(['median_house_value'], axis=1))
outlier_removed_lr_mse = sklearn.metrics.mean_squared_error(outlier_removed_test_data['median_house_value'], outlier_removed_lr_predictions)
outlier_removed_lr_mse
outlier_removed_lr_model_r2 = sklearn.metrics.r2_score(outlier_removed_test_data['median_house_value'], outlier_removed_lr_predictions)
outlier_removed_lr_model_r2
### 2.2.3 Linear Regression for Mean Imputed Data
mean_imputed_lr_model = LinearRegression()
mean_imputed_lr_model.fit(mean_imputed_train_data.drop(['median_house_value'], axis=1), mean_imputed_train_data['median_house_value'])
mean_imputed_lr_predictions = mean_imputed_lr_model.predict(mean_imputed_test_data.drop(['median_house_value'], axis=1))
mean_imputed_lr_mse = sklearn.metrics.mean_squared_error(mean_imputed_test_data['median_house_value'], mean_imputed_lr_predictions)
mean_imputed_lr_mse
mean_imputed_lr_model_r2 = sklearn.metrics.r2_score(mean_imputed_test_data['median_house_value'], mean_imputed_lr_predictions)
mean_imputed_lr_model_r2
### 2.2.4 Linear Regression for Median Imputed Data
median_imputed_lr_model = LinearRegression()   
median_imputed_lr_model.fit(median_imputed_train_data.drop(['median_house_value'], axis=1), median_imputed_train_data['median_house_value'])
median_imputed_lr_predictions = median_imputed_lr_model.predict(median_imputed_test_data.drop(['median_house_value'], axis=1))
median_imputed_lr_mse = sklearn.metrics.mean_squared_error(median_imputed_test_data['median_house_value'], median_imputed_lr_predictions)
median_imputed_lr_mse
median_imputed_lr_model_r2 = sklearn.metrics.r2_score(median_imputed_test_data['median_house_value'], median_imputed_lr_predictions)
median_imputed_lr_model_r2
### 2.2.5 Commentary
Among the Linear Regression models, original and outlier removed datasets look like the ones with the best results. This once again shows that mean and median imputations are really basic ways to deal with the missing data. They may not be ideal for all cases -or, well, most cases-.
## 2.3. Compare the Regression Methods (10 Pts)

Compare and contrast the performance of kNN and Linear Regression models across the different dataset versions (those attained in 1.3.). Discuss the strengths and limitations of each model based on your results
Linear Regression seems like the better option for this dataset. This might be unexpected because, well, kNN seems like a more complex method, hence it is generally expected to produce better results. But as can be seen in our example, this might not be the case for all datasets. For large datasets, Linear Regression is known to generally perform better. Our dataset has 10 features, which is not too much but we cannot call that low dimensional either. In kNN models, the distance between the neighbors become less and less meaningful as the dimensionality increases. So, this also might be the reason why Linear Regression performed better for our dataset.
# PLAGIARISM POLICY

In the interest of maintaining a fair and honest academic environment, this course strictly adheres to a zero-tolerance policy regarding plagiarism. 
Accordingly, all assignments must reflect individual effort and understanding. While abstract discussions with peers about concepts are encouraged, sharing or copying specific solutions, code, or pseudocode is not permitted and will be treated as plagiarism. This policy includes work sourced from the internet, publications, and AI tools like ChatGPT and GitHub Copilot. **MAKE USE OF THEM RESPONSIBLY**. That is, you can utilize them to enhance understanding and support your original work, **not to replace it**. Submitting work that is not entirely your own creation will be regarded as a violation of academic integrity. It is vital to use all resources, including AI, in a manner that supports your educational development without compromising the principles of academic honesty. 

If in doubt, do not hesitate to seek guidance from the course staff - we are here to help, with an aim to foster a learning environment based on trust, respect, and responsibility.
# REFERENCES
[1] Nugent, C. (n.d.). California Housing Prices [Data set]. Kaggle. Retrieved from https://www.kaggle.com/datasets/camnugent/california-housing-prices
